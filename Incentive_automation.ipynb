{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Incentive_automation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zHviIK9Pk1n",
        "outputId": "fd1ba5aa-c6b6-4933-eb74-934c56a232c5"
      },
      "source": [
        "!pip install arrow\n",
        "from google.colab import auth, files, drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import arrow\n",
        "import google.auth\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_storage\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "#Authentificating user.\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: arrow in /usr/local/lib/python3.6/dist-packages (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from arrow) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.0->arrow) (1.15.0)\n",
            "Authenticated\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICFP5-xban_o"
      },
      "source": [
        "#Making directories for new incentive files.\n",
        "today=arrow.now().format('MMDDYY')\n",
        "today_path='QC- '+today\n",
        "\n",
        "weekend_dir='/content/drive/My Drive/Incentive QCs/'+today_path+'/weekends'\n",
        "weekday_dir='/content/drive/My Drive/Incentive QCs/'+today_path+'/weekdays'\n",
        "\n",
        "os.makedirs('/content/drive/My Drive/Incentive QCs/'+today_path)\n",
        "os.makedirs(weekend_dir)\n",
        "os.makedirs(weekday_dir)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYeWn0CTPmDH"
      },
      "source": [
        "#Reading up the file with the weekly proposal.\n",
        "os.chdir('/content/drive/MyDrive/')\n",
        "incentive_columns=columns=list(pd.read_csv(\"/content/drive/MyDrive/QC-112320/incentives/11_20_20_FIS_CFA_v1.csv\").columns)\n",
        "incentive_columns=[x.lower() for x in incentive_columns]\n",
        "\n",
        "df=pd.read_csv(\"proposal.csv\")\n",
        "df=df.dropna(how = 'all')\n",
        "columns=list(df.columns[:-1])\n",
        "df=df[columns]\n",
        "\n",
        "#Reading up the file with places uuids for location-specific incentives.\n",
        "mcd=pd.read_csv('/content/drive/MyDrive/incentives_creation/McD_uuids.csv')\n",
        "sgf=pd.read_csv('/content/drive/MyDrive/incentives_creation/SGF_uuids.csv')\n",
        "cfa=pd.read_csv('/content/drive/MyDrive/incentives_creation/CFA_uuids.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9_gng76UAn"
      },
      "source": [
        "#Reading the info about performance from last week (that we need for guaranteed earnings calculation), couriers' average earnings and georegions.\n",
        "\n",
        "georegions=\"\"\"SELECT DISTINCT \n",
        "case when name in ('Manhattan, New York City') then 'New York City'\n",
        "  else name end as name\n",
        ", id\n",
        ", timezone\n",
        ", market_id\n",
        ",name as name2\n",
        "FROM `datafall-prod.fleet_incentive.geo_regions`\"\"\"\n",
        "\n",
        "\n",
        "credentials, your_project_id = google.auth.default(\n",
        "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        ")\n",
        "\n",
        "bqclient = bigquery.Client(credentials=credentials, project=\"datafall-fulfillment\")\n",
        "bqstorageclient = bigquery_storage.BigQueryReadClient(credentials=credentials)\n",
        "\n",
        "georegions = bqclient.query(georegions).result().to_dataframe()\n",
        "#Some states are written with comma and some without after city name, which prevents it from a correct joining.\n",
        "geo=georegions\n",
        "geo = geo.replace(',','', regex=True)\n",
        "\n",
        "#Couriers average earnings.\n",
        "avg_earnings = \"\"\"select case when j.market in ('Dallas / Ft. Worth') then 'Dallas / Ft. Worth, Dallas' else j.market end, cm.id as market_id\n",
        "     , avg(courier_price) as avg_courier_price\n",
        "  from `postmates-reporting.stats.job` j\n",
        "      left join `datafall-prod.postal_main.core_market` as cm\n",
        "        on cm.name = j.market\n",
        " where complete is true\n",
        "   and date(job_dt_local) >=date_sub(current_date(),interval 28 day)\n",
        "   and date(job_dt_local) < date(current_timestamp())\n",
        "     and j.fsm_state in ('DidCompleteDropoff','DidAdminCancel','DidCustomerCancel','DidDispatchCancel','DidDispatchRequestException')\n",
        "    and j.fraud_canceled is false\n",
        "    and j.charge_state != 'auth_failed'\n",
        "    and j.is_pickup is false\n",
        "    and j.is_return_job is false\n",
        " group by 1,2\n",
        " order by 1,2\"\"\"\n",
        "\n",
        "avg_earnings = bqclient.query(avg_earnings).result().to_dataframe()\n",
        "\n",
        "#4days.\n",
        "\n",
        "days4 = \"\"\"With l28_couriers as\n",
        "  (select courier_uuid,\n",
        "  market,\n",
        "  job_id,\n",
        "  job_dt_local\n",
        "  from `postmates-reporting.stats.job` j\n",
        "  where complete is true\n",
        "  and date(job_dt_local) >=date_sub(current_date(),interval 28 day)\n",
        "  and date(job_dt_local) < date(current_timestamp())\n",
        "  and j.fsm_state in ('DidCompleteDropoff','DidAdminCancel','DidCustomerCancel','DidDispatchCancel','DidDispatchRequestException')\n",
        "  and j.fraud_canceled is false\n",
        "  and j.charge_state != 'auth_failed'\n",
        "  and j.is_pickup is false\n",
        "  and j.is_return_job is false)\n",
        "\n",
        "---------------------------------------------------------------------------------------------\n",
        " ,peak_deliveries as\n",
        "---------------------------------------------------------------------------------------------\n",
        "  (select market, courier_uuid,\n",
        "  case  \n",
        "  when extract(dayofweek from date(job_dt_local)) in (5,6,7,1) and date(job_dt_local)>=date_sub(DATE_TRUNC(CURRENT_DATE(), WEEK(MONDAY)),interval 7 day) then '4day' end as tag,\n",
        "  count(job_id) as jobs\n",
        "  from l28_couriers\n",
        "  group by 1,2,3\n",
        "  order by 1,2,3\n",
        "  \n",
        "  ) \n",
        "\n",
        "select  distinct market, tag,  CONCAT(market, \"_\", tag) as concatenated,      PERCENTILE_DISC(jobs,0.97)\n",
        "            OVER ( PARTITION BY market,tag ) AS PercentileDisc97\n",
        "    FROM\n",
        "(select * from peak_deliveries\n",
        " where tag is not null)\n",
        "\n",
        "\n",
        " order by 4 desc\n",
        " \"\"\"\n",
        "days4 = bqclient.query(days4).result().to_dataframe()\n",
        "\n",
        "#Peak incentives.\n",
        "\n",
        "peak=\"\"\"with peak_deliveries_s1 as (\n",
        "  \n",
        "  select\n",
        "      market\n",
        "    , courier_uuid\n",
        "    , date(job_dt_local) as dt\n",
        "    , case\n",
        "\n",
        "        -- Monday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 2 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'mon_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 2 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'mon_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 2 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'mon_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 2 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'mon_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 2 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'mon_night'\n",
        "    \n",
        "        -- Tuesday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 3 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'tues_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 3 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'tues_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 3 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'tues_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 3 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'tues_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 3 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'tues_night'\n",
        "    \n",
        "        -- Wednesday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 4 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'wed_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 4 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'wed_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 4 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'wed_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 4 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'wed_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 4 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'wed_night'\n",
        "        \n",
        "        -- Thursday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 5 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'thur_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 5 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'thur_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 5 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'thur_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 5 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'thur_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 5 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'thur_night'\n",
        "        \n",
        "        -- Friday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 6 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'fri_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 6 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'fri_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 6 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'fri_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 6 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'fri_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 6 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'fri_night'\n",
        "    \n",
        "        -- Saturday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 7 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'sat_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 7 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'sat_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 7 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'sat_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 7 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'sat_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 7 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'sat_night'\n",
        "        \n",
        "        -- Sunday\n",
        "        when extract(dayofweek from date(job_dt_local)) = 1 and time(job_dt_local) between \"08:30:00\" and \"10:30:00\" then 'sun_morning'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 1 and time(job_dt_local) between \"10:30:00\" and \"13:30:00\" then 'sun_lunch'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 1 and time(job_dt_local) between \"13:30:00\" and \"16:30:00\" then 'sun_noon'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 1 and time(job_dt_local) between \"16:30:00\" and \"21:30:00\" then 'sun_dinner'\n",
        "        when extract(dayofweek from date(job_dt_local)) = 1 and time(job_dt_local) between \"21:30:00\" and \"23:30:00\" then 'sun_night'\n",
        "      end as tag\n",
        "    , count(distinct job_uuid) as jobs\n",
        "  \n",
        "  from `postmates-reporting.stats.job` j\n",
        "\n",
        "  where 1 = 1\n",
        "    and complete is true\n",
        "    and j.fsm_state in ('DidCompleteDropoff','DidAdminCancel','DidCustomerCancel','DidDispatchCancel','DidDispatchRequestException')\n",
        "    and j.fraud_canceled is false\n",
        "    and j.charge_state != 'auth_failed'\n",
        "    and j.is_pickup is false\n",
        "    and j.is_return_job is false\n",
        "    \n",
        "    -- look back 2 weeks (starting from last monday)\n",
        "    and date(job_dt_local) < date_sub(date_trunc(current_date(\"America/Los_Angeles\"), week(monday)), interval 1 week)\n",
        "    and date(job_dt_local) >= date_sub(date_trunc(current_date(\"America/Los_Angeles\"), week(monday)), interval 3 week)\n",
        "\n",
        "  group by 1, 2, 3, 4\n",
        "),\n",
        "\n",
        "peak_deliveries as (\n",
        "\n",
        "  select\n",
        "      market\n",
        "    , courier_uuid\n",
        "    , tag\n",
        "    , avg(jobs) jobs\n",
        "  \n",
        "  from peak_deliveries_s1\n",
        "  \n",
        "  group by 1, 2, 3\n",
        "\n",
        ")\n",
        "\n",
        "select distinct \n",
        "    market\n",
        "  , tag\n",
        "  , CONCAT(market, \"_\", tag) as concatenated\n",
        "  , ceil(PERCENTILE_DISC(jobs, 0.85) OVER ( PARTITION BY market,tag )) AS PercentileDisc85\n",
        "\n",
        "FROM peak_deliveries\n",
        "\n",
        "where 1 = 1\n",
        "  and tag is not null\n",
        "  and market in (\"Los Angeles\", \"Phoenix\", \"San Diego\", \"Long Beach\", \"Orange County\", \"San Bernardino\", \"San Francisco\", \"Portland\")\n",
        "order by 4 desc\"\"\"\n",
        "\n",
        "peak = bqclient.query(peak).result().to_dataframe()\n",
        "\n",
        "#Market ids.\n",
        "markets=\"SELECT distinct id as market_id, name as market, id as market_id2 FROM `datafall-prod.postal_main.core_market`\"\n",
        "markets = bqclient.query(markets).result().to_dataframe()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6PcMvMkcQAd"
      },
      "source": [
        "#Location specific\n",
        "def loc_spec(df):\n",
        "  loc_specific = ['McD_BPD', 'SGF_NYC', 'CFA_BPD']\n",
        "  uuids=[mcd, sgf, cfa]\n",
        "  today=arrow.now().format('MMDDYY')\n",
        "  for index, store in enumerate(loc_specific):\n",
        "\n",
        "    temp=df[df['Name']==store]\n",
        "    incentive=pd.DataFrame(columns=incentive_columns)\n",
        "    incentive['place_uuids'],incentive['Market']=uuids[index]['place_uuids'],uuids[index]['Market']\n",
        "    incentive['supports_flexible_enrollments']=False\n",
        "    incentive['incentive_type']=list(temp['Incentive_type'])[0]\n",
        "    incentive['name'],incentive['description']=list(temp['Name'])[0],list(temp['Name'])[0]\n",
        "    incentive['payout']=int(temp['Payout'])\n",
        "    incentive['enrollment_start_dt']=pd.to_datetime(list(temp['Enrollement start date'])[0])\n",
        "    incentive['enrollment_end_dt']=pd.to_datetime(list(temp['Enrollement end date'])[0])\n",
        "    incentive['payout_amount']=incentive['payout']*100  \n",
        "    incentive['canvas_id']=today+'_canvas_'+ store\n",
        "    incentive['variant_id']=today+'_variant_'+ store\n",
        "    incentive=pd.merge(incentive, geo, left_on='Market', right_on='name', how='left')\n",
        "    incentive['geo_region_id']=incentive['id']\n",
        "    incentive['timezone_x']=incentive['timezone_y']\n",
        "    incentive=incentive.iloc[:, : 15]\n",
        "    incentive=incentive.rename(columns = {'name_x':'name', 'timezone_x':'timezone'})\n",
        "    incentive=incentive.drop_duplicates()\n",
        "    os.chdir(weekday_dir)\n",
        "    incentive.to_csv(store+'.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjmj2cafcjFZ"
      },
      "source": [
        "def mon_thurs(df, avg_earnings):\n",
        "  avg_earnings=avg_earnings\n",
        "  today=arrow.now().format('MMDDYY')\n",
        "  temp=df[df['Name']=='mon_thurs']\n",
        "  temp.columns=[x.lower() for x in temp.columns]\n",
        "  incentive=pd.DataFrame(columns=incentive_columns)\n",
        "  markets_mt=str(temp['market'][0])\n",
        "  markets_mt=markets_mt.split(\",\")\n",
        "  markets_mt=list(itertools.chain.from_iterable(itertools.repeat(x, 8) for x in markets_mt))\n",
        "  incentive['market']=markets_mt\n",
        "  incentive['incentive_type']='Guaranteed Earnings'\n",
        "  incentive['name']='Peak'\n",
        "  incentive['supports_flexible_enrollments']=False\n",
        "  incentive['canvas_id']=today+'_canvas_'+ 'mon_thur_v1'\n",
        "  incentive['variant_id']=today+'_variant_'+ 'mon_thur_v1'\n",
        "  incentive=pd.merge(incentive, geo, left_on='market', right_on='name', how='left')\n",
        "  incentive['geo_region_id']=incentive['id']\n",
        "  incentive['timezone_x']=incentive['timezone_y']\n",
        "  incentive=incentive.iloc[:, : 15]\n",
        "  incentive=incentive.rename(columns = {'name_x':'name', 'timezone_x':'timezone'})\n",
        "  incentive['payout_amount']=incentive['payout']*100\n",
        "\n",
        "#Description\n",
        "\n",
        "  description=['Monday_Lunch,Monday_Dinner,Tuesday_Lunch,Tuesday_Dinner,Wednesday_Lunch,Wednesday_Dinner,Thursday_Lunch,Thursday_Dinner']\n",
        "  description=description*5\n",
        "  description=','.join(description)\n",
        "  description=description.split(',')\n",
        "  incentive['description']=description\n",
        "\n",
        "\n",
        "#Enrollment dates.\n",
        "  today = datetime.date.today()\n",
        "  next_mon= today + datetime.timedelta(days=-today.weekday(), weeks=1)\n",
        "  next_tue= today + datetime.timedelta(days=1-today.weekday(), weeks=1)\n",
        "  next_wed= today + datetime.timedelta(days=2-today.weekday(), weeks=1)\n",
        "  next_thu= today + datetime.timedelta(days=3-today.weekday(), weeks=1)\n",
        "\n",
        "  dates=[next_mon, next_tue,next_wed, next_thu]\n",
        "  dates=list(itertools.chain.from_iterable(itertools.repeat(x, 2) for x in dates))\n",
        "  dates=dates*5\n",
        "  incentive['enrollment_start_dt']=dates\n",
        "  incentive['enrollment_end_dt']=dates\n",
        "\n",
        "#Goals and payouts\n",
        "  incentive=incentive.merge(peak, on='market', how='left')\n",
        "  incentive['goals']=incentive['PercentileDisc85']\n",
        "\n",
        "  avg_earnings=pd.DataFrame(avg_earnings)\n",
        "  avg_earnings.rename({'f0_': 'market'}, axis=1, inplace=True)\n",
        "  incentive=incentive.merge(avg_earnings, on='market', how='left')\n",
        "  incentive['payout']=incentive['goals']*incentive['avg_courier_price']\n",
        "\n",
        "  incentive['payout']=incentive['payout'].round(decimals=0)\n",
        "  incentive['payout_amount']=incentive['payout']*100\n",
        "\n",
        "  today=arrow.now().format('MMDDYY')\n",
        "  name=str(today)+'_mon_thurs_v1.csv'\n",
        "  os.chdir(weekday_dir)\n",
        "  incentive.to_csv(name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gomAzndFdpUL"
      },
      "source": [
        "#Starters\n",
        "def starters(group):\n",
        "  os.chdir('/content/drive/MyDrive')\n",
        "  today=arrow.now().format('MMDDYY')\n",
        "  starters=pd.read_csv('starters.csv')\n",
        "  starters['canvas_id']=str(today)+'_canvas_Starters_Tier'+str(group)\n",
        "  starters['variant_id']=str(today)+'_canvas_Starters_Tier'+str(group)\n",
        "  today = datetime.date.today()\n",
        "  next_fri= today + datetime.timedelta(days=4-today.weekday(), weeks=0)\n",
        "  next_thu= today + datetime.timedelta(days=3-today.weekday(), weeks=1)\n",
        "  starters['enrollment_start_dt']=next_fri\n",
        "  starters['enrollment_end_dt']=next_thu\n",
        "  dir='/content/drive/My Drive/Incentive QCs/'+today_path+'/weekends'\n",
        "  os.chdir(dir)\n",
        "  name=str(today)+'_Starters_Tier_'+str(group)+'_v1.csv'\n",
        "  os.chdir(weekend_dir)\n",
        "  starters.to_csv(name)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI_RwUUceci3"
      },
      "source": [
        "def peaks(df, peak, avg_earnings):\n",
        "  today=arrow.now().format('MMDDYY')\n",
        "  temp=df[df['Name']=='Peak']\n",
        "  temp.columns=[x.lower() for x in temp.columns]\n",
        "  incentive=pd.DataFrame(columns=incentive_columns)\n",
        "  markets=str(temp['market'][2])\n",
        "  markets=markets.split(\",\")\n",
        "  markets_all=list(itertools.chain.from_iterable(itertools.repeat(x, 6) for x in markets))\n",
        "  incentive['market']=markets_all\n",
        "  incentive['incentive_type']='Guaranteed Earnings'\n",
        "  incentive['name']='Peak'\n",
        "  incentive['supports_flexible_enrollments']=False  \n",
        "  incentive['canvas_id']=today+'_canvas_'+ 'Peak_v1'\n",
        "  incentive['variant_id']=today+'_variant_'+ 'Peak_v1'\n",
        "  incentive=pd.merge(incentive, geo, left_on='market', right_on='name', how='left')\n",
        "  incentive['geo_region_id']=incentive['id']\n",
        "  incentive['timezone_x']=incentive['timezone_y']\n",
        "  incentive=incentive.iloc[:, : 15]\n",
        "  incentive=incentive.rename(columns = {'name_x':'name', 'timezone_x':'timezone'})\n",
        "  \n",
        "  #Description\n",
        "  description=['Friday_Lunch', 'Friday_Dinner', 'Saturday_Lunch', 'Saturday_Dinner', 'Sunday_Lunch', 'Sunday_Dinner']\n",
        "  description=description*len(markets)\n",
        "  description=','.join(description)\n",
        "  description=description.split(',')\n",
        "  incentive['description']=description\n",
        "\n",
        "  #Enrollment dates.\n",
        "  today = datetime.date.today()\n",
        "  next_fri= today + datetime.timedelta(days=4-today.weekday(), weeks=0)\n",
        "  next_sat= today + datetime.timedelta(days=5-today.weekday(), weeks=0)\n",
        "  next_sun= today + datetime.timedelta(days=6-today.weekday(), weeks=0)\n",
        "\n",
        "  dates=[next_fri, next_sat,next_sun]\n",
        "  dates=list(itertools.chain.from_iterable(itertools.repeat(x, 2) for x in dates))\n",
        "  dates=dates*len(markets)\n",
        "  incentive['enrollment_start_dt']=dates\n",
        "  incentive['enrollment_end_dt']=dates\n",
        "\n",
        "  #Goals and payouts\n",
        "  incentive=incentive.merge(peak, on='market', how='left')\n",
        "  incentive['goals']=incentive['PercentileDisc85']\n",
        "\n",
        "  avg_earnings=pd.DataFrame(avg_earnings)\n",
        "  avg_earnings.rename({'f0_': 'market'}, axis=1, inplace=True)\n",
        "  incentive=incentive.merge(avg_earnings, on='market', how='left')\n",
        "  incentive['payout']=incentive['goals']*incentive['avg_courier_price']\n",
        "\n",
        "  incentive['payout']=incentive['payout'].round(decimals=0)\n",
        "  incentive['payout_amount']=incentive['payout']*100\n",
        "  name=str(today)+'_Peak_v1.csv'\n",
        "  os.chdir(weekday_dir)\n",
        "  incentive.to_csv(name)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O78JgZmp2eNi"
      },
      "source": [
        "def react(df):\n",
        "  os.chdir('/content/drive/MyDrive')\n",
        "  temp=df[df['Name']=='Reactivation_BPDs']\n",
        "  temp.columns=[x.lower() for x in temp.columns]\n",
        "  incentive=pd.DataFrame(columns=incentive_columns)\n",
        "\n",
        "  markets=str(temp['market'][3])\n",
        "  markets=markets.split(\",\")\n",
        "  markets_all=list(itertools.chain.from_iterable(itertools.repeat(x, 6) for x in markets))  \n",
        "\n",
        "  #Markets, timezone, incentive type, canvas, and variant.\n",
        "  incentive['market']=markets_all\n",
        "  incentive['incentive_type']='Bonus Per Delivery'\n",
        "  incentive['name']='Reactivation_BPDs'\n",
        "  incentive['supports_flexible_enrollments']=False\n",
        "  incentive['canvas_id']=today+'_canvas_'+ 'React_v1'\n",
        "  incentive['variant_id']=today+'_variant_'+ 'React_v1'\n",
        "  incentive=pd.merge(incentive, geo, left_on='market', right_on='name', how='left')\n",
        "  incentive['geo_region_id']=incentive['id']\n",
        "  incentive['timezone_x']=incentive['timezone_y']\n",
        "  incentive=incentive.iloc[:, : 15]\n",
        "  incentive=incentive.rename(columns = {'name_x':'name', 'timezone_x':'timezone'})\n",
        "\n",
        "  #Description\n",
        "  description=['Friday_Lunch', 'Friday_Dinner', 'Saturday_Lunch', 'Saturday_Dinner', 'Sunday_Lunch', 'Sunday_Dinner']\n",
        "  description=description*len(markets)\n",
        "  description=','.join(description)\n",
        "  description=description.split(',')\n",
        "  incentive['description']=description\n",
        "\n",
        "  markets=str(temp['market'][3])\n",
        "  markets=markets.split(\",\")\n",
        "  markets_all=list(itertools.chain.from_iterable(itertools.repeat(x, 6) for x in markets))\n",
        "\n",
        "  #Enrollement date\n",
        "  incentive['enrollment_start_dt']=dates\n",
        "  incentive['enrollment_end_dt']=dates\n",
        "\n",
        "  #Payouts\n",
        "  lunch=int(temp['payout'][3][0])\n",
        "  dinner=int(temp['payout'][3][2])\n",
        "\n",
        "  incentive.loc[incentive['description'].str.contains(\"Lunch\"), 'payout'] = lunch\n",
        "  incentive.loc[incentive['description'].str.contains(\"Dinner\"), 'payout'] = dinner\n",
        "\n",
        "  incentive['payout_amount']=incentive['payout']*100\n",
        "  name=str(today)+'_react_v1'\n",
        "  dir='/content/drive/My Drive/Incentive QCs/'+today_path+'/weekends'\n",
        "  os.chdir(dir)\n",
        "  os.chdir(weekday_dir)\n",
        "  incentive.to_csv(name)  \n"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}